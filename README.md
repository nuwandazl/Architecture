# Архитектура информационной системы Google
Google – это поисковая система с дополнительными инструментами и сервисами. 

## Платформа
* Linux
* Большое разнообразие языков программирования: Python, Java, C++

## Статистика
* На 2021 год Google оценивается в 1,000,000 выделенных серверов, что превышает долю в 2% от всех серверов в мире.
* За 2020 год проиндексировано более 10 миллиардов страниц.
* На момент написания оригинала Google включает в себя более 200 GFS кластеров. Один кластер может состоять из 1000 или даже 5000 компьютеров
* Десятки и сотни тысяч компьютеров получают данные из GFS кластеров, которые насчитывают более 5 петабайт дискового пространства. Суммарные пропускная способность операций записи и чтения между дата центрами может достигать 40 гигабайт в секунду
* BigTable позволяет хранить миллиарды ссылок (URL), сотни терабайт снимков со спутников, а также настройки миллионов пользователей

## Стек
Google визуализирует свою инфраструктуру в виде трехслойного стека:
* Продукты: поиск, реклама, электронная почта, карты, видео, чат, блоги
* Распределенная инфраструктура системы:GFS, MapReduce и BigTable
* Вычислительные платформы: множество компьютеров во множестве датацентров
* Легкое развертывание для компании при низком уровне издержек
* Больше денег вкладывается в оборудование для исключения возможности потерь данных

## Надежное хранение данных с помощью GFS
* Надежное масштабируемое хранение данных крайне необходимо для любого приложения. GFS является основой их платформы хранения информации
* GFS - большая распределенная файловая система, способная хранить и обрабатывать огромные объемы информации
* Зачем строить что-либо самим вместо того, чтобы просто взять это с полки? Они контролируют абсолютно всю систему и именно эта платформа отличает их от всех остальных.

Она представляет собой:
* высокую надежность дата центров
* масштабируемость до тысяч сетевых узлов – высокую пропускную способность операций чтения и записи
* поддержку больших блоков данных, размер которых может измеряться в гигабайтах
* эффективное распределение операций между датацентрами для избежания возникновения "узких мест" в системе
В системе существуют мастер-сервера и сервера, собственно хранящие информацию:
* Мастер-сервера хранят метаданные для всех файлов. Сами данные хранятся блоками по 64 мегабайта на остальных серверах. Клиенты могут выполнять операции с метаданными на мастер-серверах, чтобы узнать на каком именно сервере расположены необходимые данные.
* Для обеспечения надежности один и тот же блок данных хранится в трех экземплярах на разных серверах, что обеспечивает избыточность на случай сбоев в работе какого-либо сервера.
* Новые приложения могут пользоваться как существующими кластерами, так и новыми, созданными специально для них.
* Ключ успеха заключается в том, чтобы быть уверенными в том, что у людей есть достаточно вариантов выбора для реализации их приложений. GFS может быть настроена для удовлетворения нужд любого конкретного приложения.

## Работаем с данными при помощи MapReduce
* Теперь, когда у нас есть отличная система хранения, что же делать с такими объемами данных? Допустим, у нас есть много терабайт данных, равномерно распределенных между 1000 компьютерами. Коммерческие базы данных не могут эффективно масштабироваться до такого уровня, именно в такой ситуации в дело вступает технология MapReduce.
* MapReduce является программной моделью и соответствующей реализацией обработки и генерации больших наборов данных. Пользователи могут задавать функцию, обрабатывающую пары ключ/значение для генерации промежуточных аналогичных пар, и сокращающую функцию, которая объединяет все промежуточные значения, соответствующие одному и тому же ключу. Многие реальные задачи могут быть выражены с помощью этой модели. Программы, написанные в таком функциональном стиле автоматически распараллеливаются и адаптируются для выполнения на обширных кластерах. Система берет на себя детали разбиения входных данных на части, составления расписания выполнения программ на различных компьютерах, управления ошибками, и организации необходимой коммуникации между компьютерами. Это позволяет программистам, не обладающим опытом работы с параллельными и распределенными системами, легко использовать все ресурсы больших распределенных систем.
* Зачем использовать MapReduce? – Отличный способ распределения задач между множеством компьютеров – Обработка сбоев в работе – Работа с различными типами смежных приложений, таких как поиск или реклама. Возможно предварительное вычисление и обработка данных, подсчет количества слов, сортировка терабайт данных и так далее – Вычисления автоматически приближаются к источнику ввода-вывода
MapReduce использует три типа серверов:
* Master: назначают задания остальным типам серверов, а также следят за процессом их выполнения
* Map: принимают входные данные от пользователей и обрабатывают их, результаты записываются в промежуточные файлы
* Reduce: принимают промежуточные файлы от Map-серверов и сокращают их указанным выше способом
* Например, мы хотим посчитать количество слов на всех страницах. Для этого нам необходимо передать все страницы, хранимые в GFS, на обработку в MapReduce. Этот процесс будет происходить на тысячах машин одновременно с полной координацией действий, в соответствии с автоматически составленным расписанием выполняемых работ, обработкой потенциальных ошибок, и передачей данных выполняемыми автоматически.
* Последовательность выполняемых действий выглядела бы следующим образом: GFS → Map → перемешивание → Reduce → запись результатов обратно в GFS
* Технология MapReduce состоит из двух компонентов: соответственно map и reduce. Map отображает один набор данных в другой, создавая тем самым пары ключ/значение, которпыми в нашем случае являются слова и их количества.
* В процессе перемешивания происходит агрегирование типов ключей.
* Reduction в нашем случае просто суммирует все результаты и возвращает финальный результат.
* В процессе индексирования Google подвергает поток данных обработке около 20 разных механизмов сокращения. Сначала идет работа над всеми записями и агрегированными ключами, после чего результат передается следующему механизму и второй механизм уже работает с результатами работы первого, и так далее.
* Программы могут быть очень маленькими, всего лишь от 20 до 50 строк кода.
* Единственной проблемой могут быть "отстающие компьютеры". Если один компьютер работает существенно медленнее, чем все остальные, это будет задерживать работу всей системы в целом.
* Транспортировка данных между серверами происходит в сжатом виде. Идея заключается в том, что ограничивающим фактором является пропускная способность канала и ввода-вывода, что делает резонным потратить часть процессорного времени на компрессию и декомпрессию данных.


## Хранение структурированных данных в BigTable
* BigTable является крупномасштабной, устойчивой к потенциальным ошибкам, самоуправляемой системой, которая может включать в себя терабайты памяти и петабайты данных, а также управлять миллионами операций чтения и записи в секунду.
* BigTable представляет собой распределенный механизм хэширования, построенный поверх GFS, а вовсе не реляционную базу данных и, как следствие, не поддерживает SQL-запросы и операции типа Join.
* Она предоставляет механизм просмотра данных для получения доступа к структурированным данным по имеющемуся ключу. GFS хранит данные не поддающиеся пониманию, хотя многим приложениям необходимы структурированные данные.
* Коммерческие базы данных попросту не могут масштабироваться до такого уровня и, соответственно, не могут работать с тысячами машин одновременно.
* С помощью контролирования своих низкоуровневых систем хранения данных, Google получает больше возможностей по управлению и модификации их системой. Например, если им понадобится функция, упрощающая координацию работы между датацентрами, они просто могут написать ее и внедрить в систему.
* Подключение и отключение компьютеров к функционирующей системе никак не мешает ей просто работать.
* Каждый блок данных хранится в ячейке, доступ к которой может быть предоставлен как по ключу строки или столбца, так и по временной метке.
* Каждая строка может храниться в одной или нескольких таблицах. Таблицы реализуются в виде последовательности блоков по 64 килобайта, организованных в формате данных под названием SSTable.
В BigTable тоже используется три типа серверов:
* Master: распределяют таблицы по Tablet-серверам, а также следят за расположением таблиц и перераспределяют задания в случае необходимости.
* Tablet: обрабатывают запросы чтения/записи для таблиц. Они разделяют таблицы, когда те превышают лимит размера (обычно 100-200 мегабайт). Когда такой сервер прекращает функционирование по каким-либо причинам, 100 других серверов берут на себя по одной таблице и система продолжает работать как-будто ничего не произошло.
* Lock: формируют распределенный сервис ограничения одновременного доступа. Операции открытия таблицы для записи, анализа Master-сервером или проверки доступа должны быть взаимоисключающими.
* Локальная группировка может быть использована для физического хранения связанных данных вместе, чтобы обеспечить лучшую локализацию ссылок на данные.
* Таблицы по возможности кэшируются в оперативной памяти серверов.

## Программное обеспечение
Большая часть программного стека , который Google использует на своих серверах, была разработана собственными силами. По словам известного сотрудника Google, C ++ , Java , Python и (в последнее время) Go предпочтительнее других языков программирования. . Например, серверная часть Gmail написана на Java, а серверная часть Google Search написана на C ++. Google признал, что Python с самого начала играл важную роль и продолжает играть эту роль по мере роста и развития системы.

Программное обеспечение, на котором работает инфраструктура Google, включает:
* веб-сервер Google ( GWS) - настраиваемый веб-сервер на базе Linux, который Google использует для своих онлайн-сервисов.
* Системы хранения:
